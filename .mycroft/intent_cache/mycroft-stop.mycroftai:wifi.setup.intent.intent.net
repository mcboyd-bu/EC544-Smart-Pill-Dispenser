FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.41323709904862981901e+00) (1, 1.29400226732521050899e+00) (2, 1.26001067718296067000e+00) (3, 1.17968768140106217146e+00) (4, 1.21382173409490601301e+00) (5, 4.18934728986947035878e+00) (6, -2.66238685628720972431e+00) (7, 4.05122683824587870305e+00) (8, 5.75861132450540491590e+00) (9, 4.46520771474091926478e+00) (10, -2.53875773404917248754e+00) (0, -4.91504063985451267182e-01) (1, 1.74742239605791965795e-02) (2, 3.79355746399767865262e-02) (3, -6.05419007051579069478e-02) (4, -1.03768306683360747589e-01) (5, 1.35339053696702649177e+00) (6, 3.52178595400935878779e-01) (7, 1.30347798752052934645e+00) (8, -7.81372280725157047909e-02) (9, 1.36048621214950671288e+00) (10, 2.20675973403746616963e-01) (0, -1.82691687492972354434e+00) (1, -6.02585459963459357802e-01) (2, -6.16633794174570426527e-01) (3, -6.34978628621477469984e-01) (4, -4.85509498880285494948e-01) (5, -1.27322917134731028455e+01) (6, 9.03042841659700834533e-01) (7, -1.71722107470348994696e+00) (8, 5.72936498255694903747e+00) (9, 5.64705256883575934523e+00) (10, -1.88299230388176197515e+00) (0, 1.02796710478518182885e-01) (1, -9.80219626075327310488e-01) (2, -9.07621630674898316471e-01) (3, -8.42135385817587289736e-01) (4, -9.22703483349382569401e-01) (5, -9.23799906258971015305e-01) (6, -2.01635184262833389024e-01) (7, -3.36096041632977307612e-02) (8, -1.20683451783302242433e+00) (9, 8.80145017261979312195e+00) (10, -3.44206508698403768065e+00) (0, 1.40290753942539847543e+00) (1, 1.43608802168213545158e+00) (2, 1.41149837879978834465e+00) (3, 1.42355502753102003410e+00) (4, 1.29721177353107153252e+00) (5, 3.30876041635258744122e+00) (6, -3.76309422511116542509e+00) (7, 3.62343281748263024156e+00) (8, 3.78245258569916931179e+00) (9, 4.10664167162684545787e+00) (10, -1.51316348095962194265e+00) (0, 8.45325240695836810367e-01) (1, 3.51606203872790401554e-01) (2, 4.47736288119187419987e-01) (3, 4.95194191742768463627e-01) (4, 4.47017947841515606022e-01) (5, 3.20647414796034446738e+00) (6, -2.57574012105319294363e+00) (7, 4.01980082592495513438e+00) (8, 6.14826067338396775597e+00) (9, 6.12070656930088929926e+00) (10, -6.64699279820335386937e-01) (0, 1.52021624547054923227e+00) (1, 1.41518283991657911614e+00) (2, 1.40873020498596845940e+00) (3, 1.31147175638519941643e+00) (4, 1.27081571875654875114e+00) (5, 4.00533907751683049270e+00) (6, -3.65338124814883835612e+00) (7, 3.78826826175262620922e+00) (8, 4.00213559412956154659e+00) (9, 4.10144795384911642344e+00) (10, -1.57979647447892812551e+00) (0, 1.20887516477144494331e+01) (1, 2.91011650760306994634e-01) (2, 4.49890066583289782720e-01) (3, 3.47733300824298541265e-01) (4, 3.37379173089399020391e-01) (5, -2.23275208362097937753e-01) (6, -3.32487228681827495791e+00) (7, 4.51800751926635657529e-02) (8, -2.78256952850325678384e+00) (9, -5.55044460293513286508e-01) (10, 1.20960547663243919714e-01) (0, -4.86346798173292682588e-01) (1, 3.64479619156725942464e-02) (2, -4.38868430364720354953e-02) (3, 3.66235273968585073323e-02) (4, -2.89890048015706072726e-02) (5, 1.49225746309041396032e+00) (6, 1.94490062350511742906e-02) (7, 1.34806778269274385451e+00) (8, -5.10492341526663298557e-02) (9, 1.34016443125309558937e+00) (10, 1.67125722575480473164e-01) (0, -4.77799533090694950044e-01) (1, 1.36987465512164174886e-02) (2, -7.08356023913545539139e-03) (3, 2.07133936774142185522e-02) (4, -3.02207571375958487792e-02) (5, 1.26291332839413117384e+00) (6, -1.24811447262162922289e-01) (7, 1.14076198142181595152e+00) (8, 2.25228862107249364066e-02) (9, 5.69441748975441530689e-01) (10, 2.20205215919310581807e-01) (11, 1.74386336600963504084e-01) (12, 6.67316792809046321899e-01) (13, 1.98992582634363146532e-01) (14, 2.32673416449118763971e-01) (15, 2.00204893148128421076e-01) (16, 1.25244333431311666294e-01) (17, 1.83478026783649356135e-01) (18, -9.10895488691291221883e-01) (19, 7.26731969075893990961e-01) (20, 6.54551655683042743483e-01) (21, 8.50818256980860665450e-01) 
