FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.45947398216657409087e+00) (1, 3.73098968080603943243e-01) (2, 4.32445174566828960394e-01) (3, 3.47835002950751537298e-01) (4, 4.17283302656733745550e-01) (5, -9.59354539396828576159e-01) (6, -1.30056242130752730546e+00) (7, 3.06155087693792760106e+00) (8, 3.51252361887059383339e-01) (9, 2.93105583380592282783e-01) (10, 3.84362257643515559113e-01) (0, -5.55719638421490813585e+00) (1, -1.62028348727865700862e-01) (2, -1.46889230890913491390e-01) (3, -2.04336835725946908138e-01) (4, -2.74727753086729586940e-01) (5, 9.60690066835876987916e-01) (6, 1.98247244177997689052e-01) (7, 1.12668300355685402359e+00) (8, -1.31255774083647580586e-02) (9, 2.78901635163617600544e-01) (10, -3.15825280775706429548e-01) (0, 1.11379093121999095395e+00) (1, 3.54590342256770441054e-01) (2, 4.24388297710166284560e-01) (3, 4.03487847063288995741e-01) (4, 3.72473423245892831801e-01) (5, 6.44893828714376282640e-01) (6, -8.52759404480979865681e-01) (7, -2.35243229040787449335e+00) (8, -5.38416442224405877859e-01) (9, -4.01847302856918678349e-02) (10, 7.67739802137817228811e-01) (0, 8.30857202695597329978e+00) (1, 4.19219943125129723693e-01) (2, 5.09590482700944424899e-01) (3, 4.42561312008977914001e-01) (4, 4.66740390647531533386e-01) (5, -1.51577913703299288484e-01) (6, -2.77318851772700381009e-01) (7, -5.69595919963681929232e+00) (8, -6.37241876441362875561e-01) (9, -2.14885892995254797200e-02) (10, 5.36876687653156992042e-01) (0, 4.43443418988091253574e-01) (1, -9.42774046864982562255e-02) (2, 1.93694378528121192995e-02) (3, -6.95960973110671954345e-02) (4, -8.40848092642303424071e-02) (5, -2.97621561645788679229e-01) (6, 1.24273462817100915911e-01) (7, 2.41745847658467960528e+00) (8, 2.36303893783479157520e-01) (9, 7.32317227887240518314e-01) (10, 6.24400966827253212088e-02) (0, 2.66716480351795492965e+00) (1, 3.66576919752417906828e-01) (2, 3.26991225081740721770e-01) (3, 2.08236689168273397810e-01) (4, 2.00880678790866323835e-01) (5, -1.09341016131884471996e+00) (6, -6.69958531765933895663e-01) (7, 3.42485529903976448907e+00) (8, 2.41592358648851784908e-02) (9, -2.42094404048512519545e-03) (10, 1.19415448337271162815e-01) (0, -1.94145329431863467029e-01) (1, -9.19122951927048154053e-02) (2, -1.46577801078782599120e-01) (3, -1.34679432481751959472e-01) (4, -2.80952628225312972532e-01) (5, 9.78192598245140598756e-01) (6, 2.28427662407154841162e-01) (7, 1.51430210908373663603e-01) (8, -2.04314006521606167377e-01) (9, 2.09059850167598648696e-01) (10, -1.85828475456311953407e-01) (0, 1.43977450550727614775e+00) (1, 3.17479582923709369169e-01) (2, 3.39662651020346983977e-01) (3, 3.17325333553611255155e-01) (4, 2.57551053959189868436e-01) (5, -1.09785800892359630687e+00) (6, -7.90963604955669308261e-01) (7, 3.28628256480642111370e+00) (8, 3.05276844455812323975e-01) (9, -3.25533345992047515316e-02) (10, 3.38644229436651456044e-01) (0, -5.63596037580922271104e+00) (1, -2.56538700865634794468e-01) (2, -2.25482691632637011203e-01) (3, -3.15812040673621896580e-01) (4, -2.80180614994891996616e-01) (5, 9.43914500688592283950e-01) (6, 1.04320078726453790985e+00) (7, 1.30948796224775887431e+00) (8, 9.55865689527934242475e-02) (9, 3.30188200695988254285e-01) (10, -1.74413789446784456283e-01) (0, 2.71658646412004767257e+00) (1, 3.46524913245211618751e-01) (2, 3.85542292529116648048e-01) (3, 3.78727589183817880958e-01) (4, 2.93602910274039285987e-01) (5, -9.93659769179886853685e-01) (6, -6.61672189741130734042e-01) (7, 3.64144078819916128253e+00) (8, 2.47035052432630436448e-01) (9, -2.37610352822317821841e-01) (10, 1.75866022601908839063e-01) (11, 5.43255611767888724195e-01) (12, 6.43946270773565254686e-01) (13, -1.98277329645280026016e-01) (14, -4.28121338778828797178e-01) (15, -2.11006660213030411422e-01) (16, 4.86839394724564222816e-01) (17, 6.28844271016037681399e-01) (18, 5.28217941036344229566e-01) (19, 7.06268671274610904121e-01) (20, 4.69552430963711409095e-01) (21, 3.99686422971633759094e-01) 
